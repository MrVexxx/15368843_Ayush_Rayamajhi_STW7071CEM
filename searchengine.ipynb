{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd95b1b-4938-4230-a1b0-81d9aa87036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xVEXx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xVEXx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\xVEXx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports and NLTK Downloads\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import webbrowser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d604a36-f3f5-4feb-a129-04fa9dbd945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Functions\n",
    "\n",
    "# Initialize NLTK resources\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess(text):\n",
    "    tokens = re.split(r'\\W+', text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def preprocess_query(query):\n",
    "    return preprocess(query)\n",
    "\n",
    "def expand_query(query):\n",
    "    query_terms = preprocess_query(query)\n",
    "    expanded_terms = set(query_terms)\n",
    "    for term in query_terms:\n",
    "        for syn in wordnet.synsets(term):\n",
    "            for lemma in syn.lemmas():\n",
    "                expanded_terms.add(lemma.name())\n",
    "        if '-' in term:\n",
    "            expanded_terms.update(term.split('-'))\n",
    "    return ' '.join(expanded_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaed16c-701e-4fc5-88b7-c7aba670dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web crawling functions\n",
    "def polite_crawl(url, delay=5):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            time.sleep(delay)\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Failed to crawl {url}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error crawling {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def crawl_and_parse(url):\n",
    "    response = polite_crawl(url)\n",
    "    if response:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        publications = soup.find_all('div', class_='result-container')\n",
    "        results = []\n",
    "        for pub in publications:\n",
    "            title_tag = pub.find('h3', class_='title')\n",
    "            title = title_tag.text.strip() if title_tag else 'No title'\n",
    "            link = title_tag.find('a')['href'] if title_tag and title_tag.find('a') else 'No link'\n",
    "\n",
    "            author_links = []\n",
    "            link_authors = []\n",
    "            for author_tag in pub.find_all('a', class_='link person'):\n",
    "                link_authors.append(author_tag.text.strip())\n",
    "                author_links.append(author_tag['href'])\n",
    "\n",
    "            unlink_authors = [author_tag.text.strip() for author_tag in pub.find_all('span') if \"class\" not in author_tag.attrs]\n",
    "\n",
    "            if any(title.lower() in author.lower() for author in unlink_authors):\n",
    "                unlink_authors = [author.replace(title, \"\").strip() for author in unlink_authors]\n",
    "\n",
    "            authors = link_authors + unlink_authors\n",
    "            authors = list(set(authors))\n",
    "            authors = ', '.join(authors) if authors else 'No authors'\n",
    "\n",
    "            date_tag = pub.find('span', class_='date')\n",
    "            publication_date = date_tag.text.strip() if date_tag else 'No date'\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'authors': authors,\n",
    "                'author_links': author_links,  \n",
    "                'publication_date': publication_date,\n",
    "                'content': f\"{title} {authors} {publication_date}\"\n",
    "            })\n",
    "        return results\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e47141-4310-429a-a7ff-3f10b4164077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted index functions\n",
    "def create_inverted_index(documents):\n",
    "    inverted_index = defaultdict(list)\n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        content = doc['content']\n",
    "        words = preprocess(content)\n",
    "        for word in words:\n",
    "            if doc_id not in inverted_index[word]:\n",
    "                inverted_index[word].append(doc_id)\n",
    "    return inverted_index\n",
    "\n",
    "# TF-IDF functions\n",
    "def calculate_tf_idf(documents):\n",
    "    corpus = [doc['content'] for doc in documents]\n",
    "    vectorizer = TfidfVectorizer(tokenizer=preprocess)\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    return tfidf_matrix, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4b4e4e-e6d8-45c6-a44e-d690d9ee8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function\n",
    "def search(query, inverted_index, documents, tfidf_matrix, vectorizer):\n",
    "    expanded_query = expand_query(query)\n",
    "    query_vector = vectorizer.transform([expanded_query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    query_terms = set(preprocess(query))\n",
    "    regex_query = re.compile(r'\\b(?:' + '|'.join(re.escape(term) for term in query_terms) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    relevant_docs_indices = []\n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        if regex_query.search(doc['content']):\n",
    "            relevant_docs_indices.append((doc_id, cosine_similarities[doc_id]))\n",
    "\n",
    "    relevant_docs_indices = sorted(relevant_docs_indices, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = [(documents[idx], score) for idx, score in relevant_docs_indices if score > 0]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3999b9f-256d-48dc-b75f-f84e4c37cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search and display results function\n",
    "def search_and_display_results():\n",
    "    query = search_entry.get()\n",
    "    search_results = search(query, inverted_index, documents, tfidf_matrix, vectorizer)\n",
    "    for row in result_tree.get_children():\n",
    "        result_tree.delete(row)\n",
    "    \n",
    "    if not search_results:\n",
    "        result_tree.insert(\"\", \"end\", values=(\"No results found\", \"\", \"\", \"\", \"\", \"\"))\n",
    "    else:\n",
    "        for result, score in search_results:\n",
    "            author_links = ', '.join(result['author_links'])  # Join author links with ', ' for horizontal display\n",
    "            result_tree.insert(\"\", \"end\", values=(result['title'], result['link'], result['authors'], result['publication_date'], author_links, f\"{score:.2f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e3a1a8-f823-443e-95d9-1bf04372b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear function\n",
    "def clear_fields():\n",
    "    search_entry.delete(0, tk.END)\n",
    "    for row in result_tree.get_children():\n",
    "        result_tree.delete(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226f8a28-8305-44e6-8f4c-c27a4df609a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treeview click event function\n",
    "def on_treeview_click(event):\n",
    "    item = result_tree.identify('item', event.x, event.y)\n",
    "    column = result_tree.identify_column(event.x)\n",
    "    if column == '#2':\n",
    "        link = result_tree.item(item, \"values\")[1]\n",
    "        if link != 'No link':\n",
    "            webbrowser.open(link)\n",
    "    elif column == '#5':\n",
    "        author_links = result_tree.item(item, \"values\")[4].split(', ')  \n",
    "        for link in author_links:\n",
    "            if link != 'No link':\n",
    "                webbrowser.open(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b72adb-c249-416a-8a9e-06e6e2ab658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduled crawl function\n",
    "def scheduled_crawl():\n",
    "    global documents, inverted_index, tfidf_matrix, vectorizer\n",
    "    url = 'https://pureportal.coventry.ac.uk/en/organisations/eec-school-of-computing-mathematics-and-data-sciences-cmds/publications/'\n",
    "    new_documents = crawl_and_parse(url)\n",
    "    if new_documents:\n",
    "        documents.extend(new_documents)\n",
    "        inverted_index = create_inverted_index(documents)\n",
    "        tfidf_matrix, vectorizer = calculate_tf_idf(documents)\n",
    "    print(\"Scheduled crawl completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046d224b-0838-4bb9-9bc1-bc26f4b6a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scheduled tasks function\n",
    "def run_scheduled_tasks():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72919172-65a4-4b7d-baf6-47737a38f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xVEXx\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initial crawl\n",
    "url = 'https://pureportal.coventry.ac.uk/en/organisations/eec-school-of-computing-mathematics-and-data-sciences-cmds/publications/'\n",
    "documents = crawl_and_parse(url)\n",
    "inverted_index = create_inverted_index(documents)\n",
    "tfidf_matrix, vectorizer = calculate_tf_idf(documents)\n",
    "\n",
    "# Schedule the crawl task to run once a week\n",
    "schedule.every().week.do(scheduled_crawl)\n",
    "thread = threading.Thread(target=run_scheduled_tasks)\n",
    "thread.daemon = True\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1d23b-355f-4d61-ad9a-da4d4b3c7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUI\n",
    "\n",
    "# Define dark mode colors\n",
    "dark_mode = {\n",
    "    \"background_color\": \"#1e1e1e\",\n",
    "    \"foreground_color\": \"#e8e8e8\",\n",
    "    \"button_color\": \"#3c6e71\",\n",
    "    \"button_hover_color\": \"#284b63\",\n",
    "    \"entry_background_color\": \"#2d2d2d\",\n",
    "    \"entry_foreground_color\": \"#000000\",\n",
    "    \"treeview_background_color\": \"#2d2d2d\",\n",
    "    \"treeview_foreground_color\": \"#e8e8e8\",\n",
    "    \"treeview_heading_background\": \"#3c6e71\",\n",
    "    \"treeview_heading_foreground\": \"#000000\"\n",
    "}\n",
    "\n",
    "# Define light mode colors\n",
    "light_mode = {\n",
    "    \"background_color\": \"#ffffff\",\n",
    "    \"foreground_color\": \"#000000\",\n",
    "    \"button_color\": \"#dcdcdc\",\n",
    "    \"button_hover_color\": \"#b0b0b0\",\n",
    "    \"entry_background_color\": \"#f0f0f0\",\n",
    "    \"entry_foreground_color\": \"#000000\",\n",
    "    \"treeview_background_color\": \"#ffffff\",\n",
    "    \"treeview_foreground_color\": \"#000000\",\n",
    "    \"treeview_heading_background\": \"#dcdcdc\",\n",
    "    \"treeview_heading_foreground\": \"#000000\"\n",
    "}\n",
    "\n",
    "# Current mode\n",
    "current_mode = dark_mode\n",
    "\n",
    "\n",
    "# Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"CMDS Publication Search Engine\")\n",
    "root.configure(bg=current_mode[\"background_color\"])\n",
    "\n",
    "# Styles\n",
    "style = ttk.Style()\n",
    "style.theme_use(\"clam\")\n",
    "\n",
    "def apply_styles(mode):\n",
    "    root.configure(bg=mode[\"background_color\"])\n",
    "    style.configure(\"TFrame\", background=mode[\"background_color\"])\n",
    "    style.configure(\"TLabel\", background=mode[\"background_color\"], foreground=mode[\"foreground_color\"], font=(\"Arial\", 12))\n",
    "    style.configure(\"TEntry\", background=mode[\"entry_background_color\"], foreground=mode[\"entry_foreground_color\"], font=(\"Arial\", 12))\n",
    "    style.configure(\"TButton\", background=mode[\"button_color\"], foreground=mode[\"foreground_color\"], font=(\"Arial\", 12, \"bold\"))\n",
    "    style.map(\"TButton\", background=[('active', mode[\"button_hover_color\"])], foreground=[('active', mode[\"foreground_color\"])])\n",
    "    style.configure(\"Treeview\", background=mode[\"treeview_background_color\"], foreground=mode[\"treeview_foreground_color\"], font=(\"Arial\", 10), rowheight=25)\n",
    "    style.configure(\"Treeview.Heading\", background=mode[\"treeview_heading_background\"], foreground=mode[\"treeview_heading_foreground\"], font=(\"Arial\", 12, \"bold\"))\n",
    "\n",
    "apply_styles(current_mode)\n",
    "\n",
    "def toggle_mode():\n",
    "    global current_mode\n",
    "    if current_mode == dark_mode:\n",
    "        current_mode = light_mode\n",
    "        toggle_button.config(text=\"Dark Mode\")\n",
    "    else:\n",
    "        current_mode = dark_mode\n",
    "        toggle_button.config(text=\"Light Mode\")\n",
    "    apply_styles(current_mode)\n",
    "\n",
    "\n",
    "# Search frame\n",
    "search_frame = ttk.Frame(root, padding=\"10\")\n",
    "search_frame.grid(row=0, column=0, pady=(20, 10), padx=20, sticky=(tk.W, tk.E))\n",
    "\n",
    "search_label = ttk.Label(search_frame, text=\"Enter your search query:\")\n",
    "search_label.grid(row=0, column=0, sticky=tk.W, padx=(0, 10))\n",
    "\n",
    "search_entry = ttk.Entry(search_frame, width=50, style=\"TEntry\")\n",
    "search_entry.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=(0, 10))\n",
    "\n",
    "search_button = ttk.Button(search_frame, text=\"Search\", command=search_and_display_results, style=\"TButton\")\n",
    "search_button.grid(row=0, column=2, sticky=(tk.W, tk.E), padx=(0, 10))\n",
    "\n",
    "clear_button = ttk.Button(search_frame, text=\"Clear\", command=clear_fields, style=\"TButton\")\n",
    "clear_button.grid(row=0, column=3, sticky=(tk.W, tk.E), padx=(0, 10))\n",
    "\n",
    "toggle_button = ttk.Button(search_frame, text=\"Light Mode\", command=toggle_mode, style=\"TButton\")\n",
    "toggle_button.grid(row=0, column=4, sticky=(tk.W, tk.E), padx=(10, 0))\n",
    "\n",
    "# Bind Enter key to search\n",
    "search_entry.bind(\"<Return>\", lambda event: search_and_display_results())\n",
    "\n",
    "\n",
    "# Result frame\n",
    "result_frame = ttk.Frame(root, padding=\"10\")\n",
    "result_frame.grid(row=1, column=0, pady=(10, 20), padx=20, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "columns = (\"Title\", \"Link\", \"Authors\", \"Publication Date\", \"Author Links\", \"Relevance Score\")\n",
    "result_tree = ttk.Treeview(result_frame, columns=columns, show='headings', selectmode='browse')\n",
    "result_tree.heading(\"Title\", text=\"Title\")\n",
    "result_tree.heading(\"Link\", text=\"Link\")\n",
    "result_tree.heading(\"Authors\", text=\"Authors\")\n",
    "result_tree.heading(\"Publication Date\", text=\"Publication Date\")\n",
    "result_tree.heading(\"Author Links\", text=\"Author Links\") \n",
    "result_tree.heading(\"Relevance Score\", text=\"Relevance Score\")\n",
    "result_tree.column(\"Title\", width=250)\n",
    "result_tree.column(\"Link\", width=250)\n",
    "result_tree.column(\"Authors\", width=200)\n",
    "result_tree.column(\"Publication Date\", width=150)\n",
    "result_tree.column(\"Author Links\", width=250)  \n",
    "result_tree.column(\"Relevance Score\", width=150)\n",
    "result_tree.pack(expand=True, fill='both')\n",
    "result_tree.bind(\"<Double-1>\", on_treeview_click)\n",
    "\n",
    "# Adding hover effect to Treeview items\n",
    "def on_motion(event):\n",
    "    row_id = result_tree.identify_row(event.y)\n",
    "    if row_id:\n",
    "        result_tree.tag_configure('hover', background=current_mode[\"button_hover_color\"])\n",
    "        for item in result_tree.get_children():\n",
    "            result_tree.item(item, tags=())\n",
    "        result_tree.item(row_id, tags=('hover',))\n",
    "\n",
    "result_tree.bind('<Motion>', on_motion)\n",
    "\n",
    "# Grid configuration to make Treeview expand\n",
    "root.grid_rowconfigure(1, weight=1)\n",
    "root.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526e0a0-10f7-439d-a325-0954f04056c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
